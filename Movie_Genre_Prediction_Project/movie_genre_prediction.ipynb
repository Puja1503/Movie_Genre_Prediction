{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e2a91c",
   "metadata": {},
   "source": [
    "\n",
    "        Data Science: A Programming Approach\n",
    "        Mahyar S Vaghefi\n",
    "        University of Texas Arlington\n",
    "        \n",
    "        This document can only be used for class studies. \n",
    "        You are not allowed to share it in any public platform.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bc7830",
   "metadata": {},
   "source": [
    "<h1 align='center' style=\"color: darkgreen;\">Group Project - Fall 2022</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c1b6c6",
   "metadata": {},
   "source": [
    "We have worked as a team for this project. Our job was to develop a predictive model that can predict whether or not a movie is a <i>Drama</i>. In order to do so- we have used the textual features of the movie stories and created our predictive models.\n",
    "\n",
    "There are three different files, which we have used to build this project.\n",
    "\n",
    "<ol>\n",
    "    <li><b>movie_story_student_file.csv</b>: This file contains the movie stories, which has been used for model development.</li>\n",
    "    <li><b>movie_story_evaluation_file.csv</b>: This file was not used for model development purposes. We used this file after developing our predictive models and selecting our best final model. We have used our best predictive model to predict whether the movies in <b>movie story evaluation file.csv</b> belong to <b>'Drama'</b> category or <b>'Not Drama'</b> category.</li>\n",
    "    <li><b>movies.csv</b>: This file contain the movie genres.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0c2707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required libraries and modules\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e6b5c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2617cdec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131072</td>\n",
       "      <td>A girl who always tends to fall in love with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>196609</td>\n",
       "      <td>Bigfoot has come to the town of Ellwood City, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131074</td>\n",
       "      <td>At an altitude of 18,000 feet, Alaska\\'s Mount...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196611</td>\n",
       "      <td>In her first special since 2003, Ellen revisit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196613</td>\n",
       "      <td>Mike and Sulley are back at Monsters Universit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                              story\n",
       "0    131072  A girl who always tends to fall in love with t...\n",
       "1    196609  Bigfoot has come to the town of Ellwood City, ...\n",
       "2    131074  At an altitude of 18,000 feet, Alaska\\'s Mount...\n",
       "3    196611  In her first special since 2003, Ellen revisit...\n",
       "4    196613  Mike and Sulley are back at Monsters Universit..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dataframe from the file that contains movie stories\n",
    "movies_df = pd.read_csv(\"movie_story_student_file.csv\")\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57bc18e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27509</td>\n",
       "      <td>Carolina (2005)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27618</td>\n",
       "      <td>Sound of Thunder, A (2005)</td>\n",
       "      <td>Action|Adventure|Drama|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27788</td>\n",
       "      <td>Jacket, The (2005)</td>\n",
       "      <td>Drama|Mystery|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27821</td>\n",
       "      <td>Interpreter, The (2005)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27839</td>\n",
       "      <td>Ring Two, The (2005)</td>\n",
       "      <td>Drama|Horror|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                       title                                  genres\n",
       "0    27509             Carolina (2005)                          Comedy|Romance\n",
       "1    27618  Sound of Thunder, A (2005)  Action|Adventure|Drama|Sci-Fi|Thriller\n",
       "2    27788          Jacket, The (2005)           Drama|Mystery|Sci-Fi|Thriller\n",
       "3    27821     Interpreter, The (2005)                          Drama|Thriller\n",
       "4    27839        Ring Two, The (2005)           Drama|Horror|Mystery|Thriller"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dataframe from the file that contain movie titles and genres\n",
    "genre_df=pd.read_csv(\"movies.csv\")\n",
    "genre_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d33e941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>story</th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131072</td>\n",
       "      <td>A girl who always tends to fall in love with t...</td>\n",
       "      <td>131072</td>\n",
       "      <td>Jesus liebt mich (2012)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>196609</td>\n",
       "      <td>Bigfoot has come to the town of Ellwood City, ...</td>\n",
       "      <td>196609</td>\n",
       "      <td>Bigfoot The Movie (2015)</td>\n",
       "      <td>Comedy|Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131074</td>\n",
       "      <td>At an altitude of 18,000 feet, Alaska\\'s Mount...</td>\n",
       "      <td>131074</td>\n",
       "      <td>Mount St. Elias (2009)</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196611</td>\n",
       "      <td>In her first special since 2003, Ellen revisit...</td>\n",
       "      <td>196611</td>\n",
       "      <td>Ellen DeGeneres: Relatable (2018)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196613</td>\n",
       "      <td>Mike and Sulley are back at Monsters Universit...</td>\n",
       "      <td>196613</td>\n",
       "      <td>Party Central (2014)</td>\n",
       "      <td>Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                              story  movieId  \\\n",
       "0    131072  A girl who always tends to fall in love with t...   131072   \n",
       "1    196609  Bigfoot has come to the town of Ellwood City, ...   196609   \n",
       "2    131074  At an altitude of 18,000 feet, Alaska\\'s Mount...   131074   \n",
       "3    196611  In her first special since 2003, Ellen revisit...   196611   \n",
       "4    196613  Mike and Sulley are back at Monsters Universit...   196613   \n",
       "\n",
       "                               title                             genres  \n",
       "0            Jesus liebt mich (2012)                             Comedy  \n",
       "1           Bigfoot The Movie (2015)                      Comedy|Horror  \n",
       "2             Mount St. Elias (2009)                        Documentary  \n",
       "3  Ellen DeGeneres: Relatable (2018)                             Comedy  \n",
       "4               Party Central (2014)  Animation|Children|Comedy|Fantasy  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge the two dataframes using common identifier movieid and create a new dataframe\n",
    "df = pd.merge(movies_df, genre_df, left_on='movie_id', right_on='movieId')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23bafd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>story</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131072</td>\n",
       "      <td>A girl who always tends to fall in love with t...</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>196609</td>\n",
       "      <td>Bigfoot has come to the town of Ellwood City, ...</td>\n",
       "      <td>Comedy|Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131074</td>\n",
       "      <td>At an altitude of 18,000 feet, Alaska\\'s Mount...</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196611</td>\n",
       "      <td>In her first special since 2003, Ellen revisit...</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196613</td>\n",
       "      <td>Mike and Sulley are back at Monsters Universit...</td>\n",
       "      <td>Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                              story  \\\n",
       "0    131072  A girl who always tends to fall in love with t...   \n",
       "1    196609  Bigfoot has come to the town of Ellwood City, ...   \n",
       "2    131074  At an altitude of 18,000 feet, Alaska\\'s Mount...   \n",
       "3    196611  In her first special since 2003, Ellen revisit...   \n",
       "4    196613  Mike and Sulley are back at Monsters Universit...   \n",
       "\n",
       "                              genres  \n",
       "0                             Comedy  \n",
       "1                      Comedy|Horror  \n",
       "2                        Documentary  \n",
       "3                             Comedy  \n",
       "4  Animation|Children|Comedy|Fantasy  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop title column and repeating column movieid\n",
    "df= df.drop(columns=['movieId','title'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f72ebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for the null values in genre column\n",
    "find= pd.isnull(df['genres'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e56eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the rows where genre is not mentioned\n",
    "df = df[df[\"genres\"].str.contains(\"no genres listed\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a51031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a filter for drama genre \n",
    "drama = df['genres'].str.contains('Drama','drama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8021db8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a filter for not drama genre movies\n",
    "not_drama= df['genres'].str.contains('Drama','drama')==False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64ea2aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>story</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131072</td>\n",
       "      <td>A girl who always tends to fall in love with t...</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>196609</td>\n",
       "      <td>Bigfoot has come to the town of Ellwood City, ...</td>\n",
       "      <td>Comedy|Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131074</td>\n",
       "      <td>At an altitude of 18,000 feet, Alaska\\'s Mount...</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196611</td>\n",
       "      <td>In her first special since 2003, Ellen revisit...</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196613</td>\n",
       "      <td>Mike and Sulley are back at Monsters Universit...</td>\n",
       "      <td>Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                              story  \\\n",
       "0    131072  A girl who always tends to fall in love with t...   \n",
       "1    196609  Bigfoot has come to the town of Ellwood City, ...   \n",
       "2    131074  At an altitude of 18,000 feet, Alaska\\'s Mount...   \n",
       "3    196611  In her first special since 2003, Ellen revisit...   \n",
       "4    196613  Mike and Sulley are back at Monsters Universit...   \n",
       "\n",
       "                              genres  \n",
       "0                             Comedy  \n",
       "1                      Comedy|Horror  \n",
       "2                        Documentary  \n",
       "3                             Comedy  \n",
       "4  Animation|Children|Comedy|Fantasy  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the first five rows in merged dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8498375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy of dataframe in this stage for future use\n",
    "new_df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9d8d40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply filter on the dataframe to convert genres in 1 and 0 for drama and not drama \n",
    "df.genres[drama]= 1\n",
    "df.genres[not_drama]=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da49980d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18886"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show length of new dataframe\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba645eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the columns as required\n",
    "df = df.rename(columns={'movie_id':'movieid', 'genres':'DramaGenre'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6debe6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import regex module\n",
    "import re\n",
    "# function for text cleaning \n",
    "def clean_text(text):\n",
    "    # remove backslash-and subsequent charecters and digits\n",
    "    text= re.sub(r'\\\\\\w.+?\\d*','',text) \n",
    "    #remove only backslashes\n",
    "    text = re.sub(r'\\\\','',text)\n",
    "    #remove all digits from text\n",
    "    text = re.sub(r'\\d','',text)\n",
    "    #remove all non alphanumeric characters\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]','',text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6f30821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the text cleaning function to clean text in movie stories\n",
    "df['story'] = df['story'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ad22920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieid</th>\n",
       "      <th>story</th>\n",
       "      <th>DramaGenre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131072</td>\n",
       "      <td>A girl who always tends to fall in love with t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>196609</td>\n",
       "      <td>Bigfoot has come to the town of Ellwood City P...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131074</td>\n",
       "      <td>At an altitude of  feet Alaskas Mount St Elias...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196611</td>\n",
       "      <td>In her first special since  Ellen revisits her...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>196613</td>\n",
       "      <td>Mike and Sulley are back at Monsters Universit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieid                                              story DramaGenre\n",
       "0   131072  A girl who always tends to fall in love with t...          0\n",
       "1   196609  Bigfoot has come to the town of Ellwood City P...          0\n",
       "2   131074  At an altitude of  feet Alaskas Mount St Elias...          0\n",
       "3   196611  In her first special since  Ellen revisits her...          0\n",
       "4   196613  Mike and Sulley are back at Monsters Universit...          0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#assign the dataframe as main_dataset\n",
    "main_dataset = df\n",
    "#show the first five rows of dataframe\n",
    "main_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0abfcd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign the stories and dramagenre columns to seperate dataframes\n",
    "data = main_dataset['story']\n",
    "y= main_dataset['DramaGenre']\n",
    "y=y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc92914e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bigfoot has come to the town of Ellwood City PA and is causing BIG problems Now its up to three town locals to take him down  Funded by a Kickstarter campaign and filmed in Ellwood City LA Filmmaker and hometown hero Jared Show assembled a colorful cast of characters from all over the region to bring his vision to life  The movie features some of Pittsburghs most famous and best loved celebrities like Curt Wootton Pittsburgh Dad Joanie Dodds Americas Next Top Model Jim Krenn standup comic formerly of the WDVE morning show Mike Wysocki WDVE and even veteran news anchor Darieth Chisolm formerly of WPXI among others  In this comedyhorror flick mullets guns and beer are in full supply as the movie skewers the Pittsburgh Yinzer stereotype right alongside the Bigfoot myth'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show a random story from the assigned dataframe\n",
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc179832",
   "metadata": {},
   "source": [
    "#### Building models for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03e98452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required packages and modules\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aebdf546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score,f1_score, recall_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d52d56b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset in train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,y, test_size=.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "30c450fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare the five fold cross validation\n",
    "cv = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "id": "73e073f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the count vectorizer \n",
    "count_vec= CountVectorizer(stop_words='english',  max_df=0.6,ngram_range=(1,3))\n",
    "#fit the training data with count vectorizer\n",
    "cv_train= count_vec.fit_transform(X_train)\n",
    "#transform the count vectorizer with test data\n",
    "cv_test=count_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "id": "7a760cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the tfidf vectorizer\n",
    "tfidf_vec= TfidfVectorizer(stop_words='english', max_df=0.6,ngram_range=(1,3))\n",
    "#fit the tfidf vectorizer with training data\n",
    "tfidf_train= tfidf_vec.fit_transform(X_train)\n",
    "#transform the tfidf vectorizer using test data\n",
    "tfidf_test=tfidf_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "id": "d4610941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bays Accuracy score with Countvectorizer:  68.27\n",
      "Multinomial Naive Bays Accuracy score with Tfidfvectorizer:  67.05\n"
     ]
    }
   ],
   "source": [
    "#import the multinomial naive bays modle \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#assign a name to the model\n",
    "count_nb = MultinomialNB()\n",
    "#fit the model with count vectorizer training data output vector\n",
    "count_nb.fit(cv_train,y_train)\n",
    "#predict with count vectorizer test data output vector\n",
    "count_y_test_hat=count_nb.predict(cv_test)\n",
    "#get the accuracy score for this prediction\n",
    "count_nb_score = accuracy_score(y_test, count_y_test_hat)\n",
    "\n",
    "#assign a name to the model\n",
    "tfidf_nb = MultinomialNB()\n",
    "#fit the model with tfidf vectorizer training data output vector\n",
    "tfidf_nb.fit(tfidf_train,y_train)\n",
    "#predict with tfidf vectorizer test data output vector\n",
    "tfidf_y_test_hat=count_nb.predict(tfidf_test)\n",
    "#get the accuracy score for this prediction\n",
    "tfidf_nb_score = accuracy_score(y_test, tfidf_y_test_hat)\n",
    "\n",
    "#print accuracy scores of multinomialNB model with countvectorizer and tfidfvectorizer\n",
    "print(\"Multinomial Naive Bays Accuracy score with Countvectorizer: \",round(count_nb_score*100,2))\n",
    "print(\"Multinomial Naive Bays Accuracy score with Tfidfvectorizer: \",round(tfidf_nb_score*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "id": "e5c25e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC Accuracy score with Tfidfvectorizer:  69.98\n"
     ]
    }
   ],
   "source": [
    "#import linear SVC model\n",
    "from sklearn.svm import LinearSVC\n",
    "#assign a name to the model\n",
    "tfidf_svc= LinearSVC()\n",
    "#fit the model with tfidf vectorizer training data output vector\n",
    "tfidf_svc.fit(tfidf_train,y_train)\n",
    "#predict with tfidf vectorizer test data output vector\n",
    "tfidf_svc_y_hat = tfidf_svc.predict(tfidf_test)\n",
    "#get the accuracy score for this prediction\n",
    "tfidf_svc_score= accuracy_score(y_test, tfidf_svc_y_hat)\n",
    "\n",
    "#print accuracy score of linear SVC model with tfidfvectorizer\n",
    "print(\"Linear SVC Accuracy score with Tfidfvectorizer: \",round(tfidf_svc_score*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "id": "e549eceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy score with Tfidfvectorizer:  69.7\n"
     ]
    }
   ],
   "source": [
    "#import Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#assign a name to the model\n",
    "tfidf_lr= LogisticRegression(max_iter=300, C=10000)\n",
    "#fit the model with tfidf vectorizer training data output vector\n",
    "tfidf_lr.fit(tfidf_train,y_train)\n",
    "#predict with tfidf vectorizer test data output vector\n",
    "tfidf_lr_y_hat = tfidf_lr.predict(tfidf_test)\n",
    "#get the accuracy score for this prediction\n",
    "tfidf_lr_score= accuracy_score(y_test, tfidf_lr_y_hat)\n",
    "#print accuracy score of logistic regression model with tfidfvectorizer\n",
    "print(\"Logistic Regression Accuracy score with Tfidfvectorizer: \",round(tfidf_lr_score*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d4bf3a",
   "metadata": {},
   "source": [
    "<ul><h4>Using Lemmatization of text</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "id": "1d0bb3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the modules\n",
    "from html import unescape\n",
    "import spacy\n",
    "#load the spacy module\n",
    "spacy.load('en_core_web_sm')\n",
    "#define lemmatizer\n",
    "lemmatizer = spacy.lang.en.English()\n",
    "\n",
    "# defining new tokenizer\n",
    "def my_tokenizer(doc):\n",
    "    tokens = lemmatizer(doc)\n",
    "    return([token.lemma_ for token in tokens])\n",
    "\n",
    "# remove html entities from docs and\n",
    "# set everything to lowercase\n",
    "def my_preprocessor(doc):\n",
    "    return(unescape(doc).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "id": "ebe15597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tfidf vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#initialize the vectorizer with preprocessor\n",
    "custom_vec = TfidfVectorizer( preprocessor=my_preprocessor, stop_words='english',\n",
    "                             ngram_range=(1,3))\n",
    "#fit the vectorizer with text data\n",
    "X = custom_vec.fit_transform(data)\n",
    "#split the dataset in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "id": "b2f16014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With preprocessing  SGDclassifier model mean accuracy score:  68.81\n"
     ]
    }
   ],
   "source": [
    "#using SGD classifier\n",
    "#calculate accuracy of model with new preprocessed data\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "model = SGDClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_test_hat = model.predict(X_test)\n",
    "print(\"With preprocessing  SGDclassifier model mean accuracy score: \",round(accuracy_score(y_test,y_test_hat) * 100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "id": "b987e3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model Best Parameter:) {'C': 3792.690190732246}\n",
      "Out of sample accuracy score of Logistic Regresseion model : 0.6961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_model = LogisticRegression()\n",
    "#define parameter for logistic regression model\n",
    "C1 = np.logspace(-4, 4,20)\n",
    "LR_params = {'C': C1}\n",
    "#define gridsearch model\n",
    "LR_grid = GridSearchCV(LR_model, LR_params, cv=cv, return_train_score = True, scoring='accuracy')\n",
    "#fit training dataset with grid\n",
    "LR_grid.fit(X_train,y_train)\n",
    "#define the best model from grid search\n",
    "LR_bestModel = LR_grid.best_estimator_\n",
    "#predict with the best model\n",
    "LR_y_test_hat = LR_bestModel.predict(X_test)\n",
    "#calculate accuracy score\n",
    "LR_out_acc = accuracy_score(y_test,LR_y_test_hat, normalize=True)\n",
    "print(\"Logistic regression model Best Parameter:) {}\".format(LR_grid.best_params_))\n",
    "print(f\"Out of sample accuracy score of Logistic Regresseion model : {LR_out_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "id": "47ef01f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With preprocessing Logistic Regression model mean accuracy score= 70.11\n",
      "With preprocessing Logistic Regression model mean precision score=  69.97\n",
      "With preprocessing Logistic Regression model mean recall score=  69.01\n",
      "With preprocessing Logistic Regression model mean f1 score=  69.74\n",
      "With preprocessing Logistic Regression model mean ROC AUC score=  77.13\n"
     ]
    }
   ],
   "source": [
    "#define the model with best model from gridsearch\n",
    "LR_model=LR_bestModel\n",
    "#calculate accuracy of model\n",
    "LR_accuracy = cross_validate(LR_model,  X_train, y_train, scoring='accuracy', cv=cv)\n",
    "#calculate precision of model\n",
    "LR_precision = cross_validate(LR_model,  X_train, y_train, scoring='precision_macro', cv=cv)\n",
    "#calculate recall score of model\n",
    "LR_recall = cross_validate(LR_model,  X_train, y_train, scoring='recall_macro', cv=cv)\n",
    "#calculate F1 score of model\n",
    "LR_f1_score = cross_validate(LR_model,  X_train, y_train, scoring='f1_weighted', cv=cv)\n",
    "#roc-auc score of model\n",
    "LR_roc_auc_score = cross_validate(LR_model,  X_train, y_train, scoring='roc_auc_ovo_weighted', cv=cv)\n",
    "#print the scores\n",
    "#print accuracy\n",
    "print(f\"With preprocessing Logistic Regression model mean accuracy score=\",round(np.mean(LR_accuracy['test_score'])*100,2) )\n",
    "#print precision score\n",
    "print(f\"With preprocessing Logistic Regression model mean precision score= \",round(np.mean(LR_precision['test_score'])*100,2) )\n",
    "#print recall score\n",
    "print(f\"With preprocessing Logistic Regression model mean recall score= \",round(np.mean(LR_recall['test_score'])*100,2) )\n",
    "#print F1 score\n",
    "print(f\"With preprocessing Logistic Regression model mean f1 score= \",round(np.mean(LR_f1_score['test_score'])*100,2) )\n",
    "#print roc-auc score\n",
    "print(f\"With preprocessing Logistic Regression model mean ROC AUC score= \",round(np.mean(LR_roc_auc_score['test_score'])*100,2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "id": "88be4f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the vectorizer with preprocessor and tokenizer \n",
    "custom_vec = TfidfVectorizer( preprocessor=my_preprocessor,tokenizer=my_tokenizer,stop_words='english',\n",
    "                             ngram_range=(1,4))\n",
    "#fit with text data\n",
    "X = custom_vec.fit_transform(data)\n",
    "#split the datasets in train and test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "id": "d0de93ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With preprocessing and lemmatization Logistic Regression model mean accuracy score= 55.39\n"
     ]
    }
   ],
   "source": [
    "#calculate accuracy of model with new lemmatized data\n",
    "LR_accuracy = cross_validate(LR_model,  X_train, y_train, scoring='accuracy', cv=cv)\n",
    "#print accuracy\n",
    "print(f\"With preprocessing and lemmatization Logistic Regression model mean accuracy score=\",round(np.mean(LR_accuracy['test_score'])*100,2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "id": "611fb7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With preprocessing and lemmatization SGDclassifier model mean accuracy score:  55.45\n"
     ]
    }
   ],
   "source": [
    "#using SGD classifier\n",
    "#calculate accuracy of model with new lemmatized data\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "model = SGDClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_test_hat = model.predict(X_test)\n",
    "print(\"With preprocessing and lemmatization SGDclassifier model mean accuracy score: \",round(accuracy_score(y_test,y_test_hat) * 100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72631d0",
   "metadata": {},
   "source": [
    "##### By using Glove 300 dimension word embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "id": "bdcd8783",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1917494it [05:25, 5899.71it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "embeddings_index = dict()\n",
    "f = open('glove.42B.300d/glove.42B.300d.txt',encoding='utf-8')\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "id": "2e23c3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\manas_nmr2rze\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|██████████| 18886/18886 [06:02<00:00, 52.04it/s] \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from tqdm import tqdm\n",
    "embeddings = []\n",
    "for text in tqdm(data):\n",
    "\n",
    "    base_embedding = np.zeros((300,))\n",
    "    word_count = 0\n",
    "    for token in word_tokenize(text):\n",
    "        token = token.lower()\n",
    "        if token in stopwords.words('english'):\n",
    "            continue\n",
    "        try:\n",
    "            base_embedding += embeddings_index[token]\n",
    "            word_count +=1\n",
    "        except:\n",
    "            continue\n",
    "    base_embedding = base_embedding/word_count\n",
    "    embeddings.append(base_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "id": "86e5af4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_we_3 = np.array(embeddings, dtype='float64')\n",
    "X_train_we_3, X_test_we_3, y_train_we_3, y_test_we_3 = train_test_split(X_we_3,y, test_size=.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "id": "2e6e08de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model mean accuracy score with 300d word embedding = 69.78\n"
     ]
    }
   ],
   "source": [
    "#initialize the logistic regression model\n",
    "LR_model_1=LogisticRegression(max_iter=1000, C=1)\n",
    "#calculate accuracy of model\n",
    "LR_accuracy_we_3 = cross_validate(LR_model_1,  X_train_we_3, y_train_we_3, scoring='accuracy', cv=cv)\n",
    "#print accuracy\n",
    "print(f\"Logistic Regression model mean accuracy score with 300d word embedding =\",round(np.mean(LR_accuracy_we_3['test_score'])*100,2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9f4d54",
   "metadata": {},
   "source": [
    "##### Using truncated SVD method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "id": "b8bc2b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "#initialize the tfidvectorizer with lemmatization\n",
    "custom_vec = TfidfVectorizer( preprocessor=my_preprocessor,stop_words='english',\n",
    "                             ngram_range=(1,3))\n",
    "X = custom_vec.fit_transform(data).astype('float32')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.3, random_state=0, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "id": "54ef648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducing the number of components with truncated SVD\n",
    "tsvd = TruncatedSVD(n_components = 100)\n",
    "X_tsvd = tsvd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "id": "45b2ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tsvd_train, X_tsvd_test, y_tsvd_train, y_tsvd_test = train_test_split(X_tsvd,y, test_size=.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "id": "3e5c5e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for SVM Classifier:  68.3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVM_model = SVC(kernel='rbf')\n",
    "SVM_model.fit(X_tsvd_train, y_tsvd_train)\n",
    "y_test_hat = SVM_model.predict(X_tsvd_test)\n",
    "print(\"Accuracy for SVM Classifier: \",round(accuracy_score(y_tsvd_test,y_test_hat) * 100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "id": "fe08b856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Neural network Classifier:  66.25\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "NN_model = MLPClassifier(solver='adam',random_state=0, max_iter=500)\n",
    "NN_model.fit(X_tsvd_train, y_tsvd_train)\n",
    "y_test_hat = NN_model.predict(X_tsvd_test)\n",
    "print(\"Accuracy for Neural network Classifier: \",round(accuracy_score(y_tsvd_test,y_test_hat) * 100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "id": "2e86cbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Random Forest Classifier:  65.97\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier Model\n",
    "#import random forest classifier model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#define the model\n",
    "RF_model= RandomForestClassifier()\n",
    "RF_model.fit(X_tsvd_train, y_tsvd_train)\n",
    "y_test_hat = RF_model.predict(X_tsvd_test)\n",
    "print(\"Accuracy for Random Forest Classifier: \",round(accuracy_score(y_tsvd_test,y_test_hat) * 100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9021fff9",
   "metadata": {},
   "source": [
    "<ul>By applying tensors on trunkated SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "id": "4f5962a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "id": "2cde6a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the tensors\n",
    "tf.convert_to_tensor( X_tsvd_train)\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(X_tsvd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "id": "0a346911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a model to add layers\n",
    "def get_model():\n",
    "  model = tf.keras.Sequential([\n",
    "    normalizer,\n",
    "    tf.keras.layers.Dense(1000, activation='relu'),\n",
    "    tf.keras.layers.Dense(500, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "id": "ea282a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14/14 [==============================] - 1s 30ms/step - loss: 0.6623 - accuracy: 0.5717\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5844 - accuracy: 0.6681\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5566 - accuracy: 0.6862\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.5309 - accuracy: 0.7064\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.5044 - accuracy: 0.7300\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4768 - accuracy: 0.7524\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 0.4391 - accuracy: 0.7781\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.4040 - accuracy: 0.8043\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 0.3726 - accuracy: 0.8210\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 30ms/step - loss: 0.3446 - accuracy: 0.8377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc3c1cb2b0>"
      ]
     },
     "execution_count": 1050,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize the model\n",
    "model = get_model()\n",
    "model.fit(X_tsvd_train, y_tsvd_train, epochs=10, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "id": "5b9d9fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 1s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "#predict with the model\n",
    "y_tsvd_test_hat = (model.predict(X_tsvd_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "id": "a0ce413b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[2381  761]\n",
      " [1156 1368]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.76      0.71      3142\n",
      "           1       0.64      0.54      0.59      2524\n",
      "\n",
      "    accuracy                           0.66      5666\n",
      "   macro avg       0.66      0.65      0.65      5666\n",
      "weighted avg       0.66      0.66      0.66      5666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "print(\"Confusion Matrix\") \n",
    "print(confusion_matrix(y_tsvd_test,y_tsvd_test_hat)) \n",
    "print(classification_report(y_tsvd_test,y_tsvd_test_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f53bc0",
   "metadata": {},
   "source": [
    "### By selecting the top genres from dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3dbeb3",
   "metadata": {},
   "source": [
    "<ul>Since our dataset is poorly balanced,we can increase the performance of our models by reducing the total number of genres in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50849ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1055, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get unique values of movie genres\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "genres=pd.DataFrame(genre_df.genres.unique())\n",
    "genres.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d07d60c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8412"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get movies contains drama in genre\n",
    "new_df.genres.str.contains('Drama'or'drama').value_counts()[True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d67f7332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10474"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get movies that does not contain drama in genre\n",
    "new_df.genres.str.contains('Drama'or'drama').value_counts()[False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e19cbc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a filter for not dram genres\n",
    "not_dr=new_df['genres'].str.contains('Drama','drama')==False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "053d4c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe with count of genres\n",
    "cout= pd.DataFrame(new_df.genres.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b38494ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Drama</th>\n",
       "      <td>3044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Documentary</th>\n",
       "      <td>2358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy</th>\n",
       "      <td>1690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy|Drama</th>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama|Romance</th>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horror</th>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy|Romance</th>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horror|Thriller</th>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy|Drama|Romance</th>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama|Thriller</th>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thriller</th>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime|Drama</th>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime|Drama|Thriller</th>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy|Horror</th>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Action|Drama</th>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Action|Thriller</th>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Animation</th>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Action</th>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama|War</th>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romance</th>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      genres\n",
       "Drama                   3044\n",
       "Documentary             2358\n",
       "Comedy                  1690\n",
       "Comedy|Drama             892\n",
       "Drama|Romance            607\n",
       "Horror                   541\n",
       "Comedy|Romance           478\n",
       "Horror|Thriller          442\n",
       "Comedy|Drama|Romance     398\n",
       "Drama|Thriller           392\n",
       "Thriller                 387\n",
       "Crime|Drama              196\n",
       "Crime|Drama|Thriller     193\n",
       "Comedy|Horror            155\n",
       "Action|Drama             152\n",
       "Action|Thriller          148\n",
       "Animation                143\n",
       "Action                   136\n",
       "Drama|War                129\n",
       "Romance                  115"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize the dataframe\n",
    "cout.head(20)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3fb74f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataset with 10 highest number of genres\n",
    "arr = cout.nlargest(10,'genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e231ff06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Drama</th>\n",
       "      <td>3044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Documentary</th>\n",
       "      <td>2358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy</th>\n",
       "      <td>1690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy|Drama</th>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama|Romance</th>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horror</th>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy|Romance</th>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horror|Thriller</th>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy|Drama|Romance</th>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drama|Thriller</th>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      genres\n",
       "Drama                   3044\n",
       "Documentary             2358\n",
       "Comedy                  1690\n",
       "Comedy|Drama             892\n",
       "Drama|Romance            607\n",
       "Horror                   541\n",
       "Comedy|Romance           478\n",
       "Horror|Thriller          442\n",
       "Comedy|Drama|Romance     398\n",
       "Drama|Thriller           392"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize the dataset\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4389f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the index of dataset\n",
    "arr['genre'] = arr.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cfc77f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the columns\n",
    "arr.columns=['count','genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "766d3f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>count</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drama</td>\n",
       "      <td>3044</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>2358</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>1690</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>892</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drama|Romance</td>\n",
       "      <td>607</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index  count          genre\n",
       "0          Drama   3044          Drama\n",
       "1    Documentary   2358    Documentary\n",
       "2         Comedy   1690         Comedy\n",
       "3   Comedy|Drama    892   Comedy|Drama\n",
       "4  Drama|Romance    607  Drama|Romance"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reset the index to add a new index\n",
    "arr=arr.reset_index()\n",
    "arr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "805559f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3044</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2358</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1690</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>892</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>607</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>541</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>478</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>442</td>\n",
       "      <td>Horror|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>398</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>392</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count                 genre\n",
       "0   3044                 Drama\n",
       "1   2358           Documentary\n",
       "2   1690                Comedy\n",
       "3    892          Comedy|Drama\n",
       "4    607         Drama|Romance\n",
       "5    541                Horror\n",
       "6    478        Comedy|Romance\n",
       "7    442       Horror|Thriller\n",
       "8    398  Comedy|Drama|Romance\n",
       "9    392        Drama|Thriller"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now drop the column named index\n",
    "arr.drop(columns=['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7e74421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataset from the original dataset where genres are in top 10 list\n",
    "mod_df=new_df[new_df['genres'].isin([i for i in arr.genre])].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "42dcfef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the index column\n",
    "mod_df=mod_df.drop(columns=['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a0517434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>story</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131072</td>\n",
       "      <td>A girl who always tends to fall in love with t...</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131074</td>\n",
       "      <td>At an altitude of 18,000 feet, Alaska\\'s Mount...</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196611</td>\n",
       "      <td>In her first special since 2003, Ellen revisit...</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196621</td>\n",
       "      <td>When a beautiful ballerina dancer, Adriana Men...</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131090</td>\n",
       "      <td>Jonas is 18-years-old and has had to repeat se...</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                              story       genres\n",
       "0    131072  A girl who always tends to fall in love with t...       Comedy\n",
       "1    131074  At an altitude of 18,000 feet, Alaska\\'s Mount...  Documentary\n",
       "2    196611  In her first special since 2003, Ellen revisit...       Comedy\n",
       "3    196621  When a beautiful ballerina dancer, Adriana Men...       Horror\n",
       "4    131090  Jonas is 18-years-old and has had to repeat se...       Comedy"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize the first five rows\n",
    "mod_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0810b573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10842, 3)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get shape of the dataset\n",
    "mod_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0fa1b1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movie_id', 'story', 'genres'], dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize the column names\n",
    "mod_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6cff7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create filters\n",
    "drama_mod = mod_df['genres'].str.contains('Drama','drama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "13e800e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create filters\n",
    "not_drama_mod= mod_df['genres'].str.contains('Drama','drama')==False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b4ec780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the columns as required\n",
    "mod_df = mod_df.rename(columns={'movie_id':'movieid', 'genres':'DramaGenre'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3a6317d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply filters to change dramagenre to 1 else 0\n",
    "mod_df.DramaGenre[drama_mod]= 1\n",
    "mod_df.DramaGenre[not_drama_mod]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dd6720e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieid</th>\n",
       "      <th>story</th>\n",
       "      <th>DramaGenre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131072</td>\n",
       "      <td>A girl who always tends to fall in love with t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131074</td>\n",
       "      <td>At an altitude of 18,000 feet, Alaska\\'s Mount...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196611</td>\n",
       "      <td>In her first special since 2003, Ellen revisit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196621</td>\n",
       "      <td>When a beautiful ballerina dancer, Adriana Men...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131090</td>\n",
       "      <td>Jonas is 18-years-old and has had to repeat se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>65558</td>\n",
       "      <td>The Recruiter takes viewers to the Louisiana c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>196631</td>\n",
       "      <td>The tense marriage between two painters is sha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>131100</td>\n",
       "      <td>David Sieveking left home years ago to make fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>196637</td>\n",
       "      <td>Three estranged sisters deal with the death of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>196639</td>\n",
       "      <td>How do we cope with the unthinkable? Tuva Novo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieid                                              story DramaGenre\n",
       "0   131072  A girl who always tends to fall in love with t...          0\n",
       "1   131074  At an altitude of 18,000 feet, Alaska\\'s Mount...          0\n",
       "2   196611  In her first special since 2003, Ellen revisit...          0\n",
       "3   196621  When a beautiful ballerina dancer, Adriana Men...          0\n",
       "4   131090  Jonas is 18-years-old and has had to repeat se...          0\n",
       "5    65558  The Recruiter takes viewers to the Louisiana c...          0\n",
       "6   196631  The tense marriage between two painters is sha...          1\n",
       "7   131100  David Sieveking left home years ago to make fi...          0\n",
       "8   196637  Three estranged sisters deal with the death of...          1\n",
       "9   196639  How do we cope with the unthinkable? Tuva Novo...          1"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vissualize the first 10 rows\n",
    "mod_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5f8b9d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10842, 3)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check shape of the new dataset\n",
    "mod_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ece47e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import regex module\n",
    "import re\n",
    "# function for text cleaning \n",
    "def clean_text(text):\n",
    "    # remove backslash-and subsequent charecters and digits\n",
    "    text= re.sub(r'\\\\\\w.+?\\d*','',text) \n",
    "    #remove only backslashes\n",
    "    text = re.sub(r'\\\\','',text)\n",
    "    #remove all digits from text\n",
    "    text = re.sub(r'\\d','',text)\n",
    "    #remove all non alphanumeric characters\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]','',text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c9b39177",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the dataset using the function\n",
    "mod_df['story'] = mod_df['story'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cdffea79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieid</th>\n",
       "      <th>story</th>\n",
       "      <th>DramaGenre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131072</td>\n",
       "      <td>A girl who always tends to fall in love with t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131074</td>\n",
       "      <td>At an altitude of  feet Alaskas Mount St Elias...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>196611</td>\n",
       "      <td>In her first special since  Ellen revisits her...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196621</td>\n",
       "      <td>When a beautiful ballerina dancer Adriana Mena...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131090</td>\n",
       "      <td>Jonas is yearsold and has had to repeat severa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieid                                              story DramaGenre\n",
       "0   131072  A girl who always tends to fall in love with t...          0\n",
       "1   131074  At an altitude of  feet Alaskas Mount St Elias...          0\n",
       "2   196611  In her first special since  Ellen revisits her...          0\n",
       "3   196621  When a beautiful ballerina dancer Adriana Mena...          0\n",
       "4   131090  Jonas is yearsold and has had to repeat severa...          0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a copy for working\n",
    "main_dataset_mod = mod_df\n",
    "main_dataset_mod.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fc6ed3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign the stories and dramagenre columns to seperate dataframes\n",
    "data_mod = main_dataset_mod['story']\n",
    "y_mod= main_dataset_mod['DramaGenre']\n",
    "y_mod=y_mod.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b8271348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'At an altitude of  feet Alaskas Mount St Elias is the destination for a trio of mountaineers determined to reach the mountains summit and to ski back down as well Mount St Elias documents their journey as they trek the fine line between bravery and madness'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize a random story from the data\n",
    "data_mod[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0d1070dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required modules and packages\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a2dce1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score,f1_score, recall_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fd1d4062",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset in train and test sets\n",
    "X_train_mod, X_test_mod, y_train_mod, y_test_mod = train_test_split(data_mod,y_mod, test_size=.3, random_state=0, stratify=y_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cfd48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define and initialize countvectorizer\n",
    "count_vec_mod= CountVectorizer(stop_words='english',min_df=.1,max_df=.9,ngram_range=(1,5))\n",
    "cv_train_mod= count_vec.fit_transform(X_train_mod)\n",
    "cv_test_mod=count_vec.transform(X_test_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b39095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define and initialize tfidf vectorizer\n",
    "tfidf_vec_mod= TfidfVectorizer(stop_words='english',min_df=.1,max_df=.9,ngram_range=(1,5))\n",
    "tfidf_train_mod= count_vec.fit_transform(X_train_mod)\n",
    "tfidf_test_mod=count_vec.transform(X_test_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "id": "4e7834d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bays Accuracy score with Countvectorizer:  71.56\n"
     ]
    }
   ],
   "source": [
    "#check accuracy with multinomial NB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "count_nb_mod = MultinomialNB()\n",
    "count_nb_mod.fit(cv_train_mod,y_train_mod)\n",
    "count_y_test_hat_mod=count_nb_mod.predict(cv_test_mod)\n",
    "count_nb_score_mod = accuracy_score(y_test_mod, count_y_test_hat_mod)\n",
    "\n",
    "\n",
    "print(\"Multinomial Naive Bays Accuracy score with Countvectorizer: \",round(count_nb_score_mod*100,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "id": "a60a356b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy score with Tfidfvectorizer:  71.63\n"
     ]
    }
   ],
   "source": [
    "#check accuracy score with logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "tfidf_lr_mod= LogisticRegression(max_iter=300, C=10000)\n",
    "tfidf_lr_mod.fit(tfidf_train_mod,y_train_mod)\n",
    "tfidf_lr_y_hat_mod = tfidf_lr_mod.predict(tfidf_test_mod)\n",
    "tfidf_lr_score_mod= accuracy_score(y_test_mod, tfidf_lr_y_hat_mod)\n",
    "\n",
    "print(\"Logistic Regression Accuracy score with Tfidfvectorizer: \",round(tfidf_lr_score_mod*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "id": "a01dde9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function for preprocessing and lemmatization\n",
    "from html import unescape\n",
    "import spacy\n",
    "\n",
    "spacy.load('en_core_web_sm')\n",
    "lemmatizer = spacy.lang.en.English()\n",
    "\n",
    "# defining new tokenizer\n",
    "def my_tokenizer(doc):\n",
    "    tokens = lemmatizer(doc)\n",
    "    return([token.lemma_ for token in tokens])\n",
    "\n",
    "# remove html entities from docs and\n",
    "# set everything to lowercase\n",
    "def my_preprocessor(doc):\n",
    "    return(unescape(doc).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "id": "46721ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement tfidf vectorizer with preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "custom_vec = TfidfVectorizer( preprocessor=my_preprocessor, stop_words='english',\n",
    "                             ngram_range=(1,5))\n",
    "X_mod = custom_vec.fit_transform(data_mod)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mod,y_mod, test_size=.3, random_state=0, stratify=y_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f97ba1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare the five fold cross validation\n",
    "cv = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "id": "c4da0ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression model Best Parameter:) {'C': 4832.930238571752}\n",
      "Out of sample accuracy score of Logistic Regresseion model : 72.15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR_model = LogisticRegression()\n",
    "#define parameter for logistic regression model\n",
    "C1 = np.logspace(-2, 4,20)\n",
    "LR_params = {'C': C1}\n",
    "#define gridsearch model\n",
    "LR_grid = GridSearchCV(LR_model, LR_params, cv=cv, return_train_score = True, scoring='accuracy')\n",
    "#fit training dataset with grid\n",
    "LR_grid.fit(X_train,y_train)\n",
    "#define the best model from grid search\n",
    "LR_bestModel = LR_grid.best_estimator_\n",
    "#predict with the best model\n",
    "LR_y_test_hat = LR_bestModel.predict(X_test)\n",
    "#calculate accuracy score\n",
    "LR_out_acc = accuracy_score(y_test,LR_y_test_hat, normalize=True)\n",
    "print(\"Logistic regression model Best Parameter:) {}\".format(LR_grid.best_params_))\n",
    "print(f\"Out of sample accuracy score of Logistic Regresseion model :\",round(LR_out_acc*100,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "id": "107544c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model mean accuracy score=  73.32\n",
      "Logistic Regression model mean precision score=  73.32\n",
      "Logistic Regression model mean recall score=  73.32\n",
      "Logistic Regression model mean f1 score=  73.32\n",
      "Logistic Regression model mean ROC AUC score=  81.31\n"
     ]
    }
   ],
   "source": [
    "#calculate accuracy of model\n",
    "LR_accuracy = cross_validate(LR_bestModel,  X_train, y_train, scoring='accuracy', cv=cv)\n",
    "#calculate precision of model\n",
    "LR_precision = cross_validate(LR_bestModel,  X_train, y_train, scoring='precision_macro', cv=cv)\n",
    "#calculate recall score of model\n",
    "LR_recall = cross_validate(LR_bestModel,  X_train, y_train, scoring='recall_macro', cv=cv)\n",
    "#calculate F1 score of model\n",
    "LR_f1_score = cross_validate(LR_bestModel,  X_train, y_train, scoring='f1_weighted', cv=cv)\n",
    "#roc-auc score of model\n",
    "LR_roc_auc_score = cross_validate(LR_bestModel,  X_train, y_train, scoring='roc_auc_ovo_weighted', cv=cv)\n",
    "#print the scores\n",
    "#print accuracy\n",
    "print(f\"Logistic Regression model mean accuracy score= \",round(np.mean(LR_accuracy['test_score'])*100,2) )\n",
    "#print precision score\n",
    "print(f\"Logistic Regression model mean precision score= \",round(np.mean(LR_precision['test_score'])*100,2) )\n",
    "#print recall score\n",
    "print(f\"Logistic Regression model mean recall score= \",round(np.mean(LR_recall['test_score'])*100,2) )\n",
    "#print F1 score\n",
    "print(f\"Logistic Regression model mean f1 score= \",round(np.mean(LR_f1_score['test_score'])*100,2) )\n",
    "#print roc-auc score\n",
    "print(f\"Logistic Regression model mean ROC AUC score= \",round(np.mean(LR_roc_auc_score['test_score'])*100,2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe24c2c",
   "metadata": {},
   "source": [
    "<ul><h4>With topic modeling</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "badb7270",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required module\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "102b121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize countvectorizer\n",
    "vect = CountVectorizer(max_features=20000, max_df=.60, \n",
    "                       stop_words=\"english\")\n",
    "X_l = vect.fit_transform(data_mod)\n",
    "n_topics = 10\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, learning_method=\"batch\",\n",
    "                                max_iter=100, random_state=0) \n",
    "document_topics = lda.fit_transform(X_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "affe3edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Logistic Regression with topic modelling:  65.45\n"
     ]
    }
   ],
   "source": [
    "#initialize and predict accuracy using logistic regression\n",
    "model = LogisticRegression(C=4833)\n",
    "X_train, X_test, y_train, y_test = train_test_split(document_topics, y_mod, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=0,\n",
    "                                                    stratify = y_mod)\n",
    "model.fit(X_train, y_train)\n",
    "y_test_hat = model.predict(X_test)\n",
    "print(\"Accuracy score of Logistic Regression with topic modelling: \",round(accuracy_score(y_test,y_test_hat) * 100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c1ff4",
   "metadata": {},
   "source": [
    "<ul><h4>With 300 dimensions word embedding using Glove</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8429bfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1917494it [03:08, 10172.18it/s]\n"
     ]
    }
   ],
   "source": [
    "#import the modules\n",
    "from tqdm import tqdm\n",
    "embeddings_index = dict()\n",
    "f = open('glove.42B.300d/glove.42B.300d.txt',encoding='utf-8')\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b4bdf212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\manas_nmr2rze\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|██████████| 10842/10842 [02:14<00:00, 80.67it/s] \n"
     ]
    }
   ],
   "source": [
    "#create the embedded array using text data\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from tqdm import tqdm\n",
    "embeddings = []\n",
    "for text in tqdm(data_mod):\n",
    "\n",
    "    base_embedding = np.zeros((300,))\n",
    "    word_count = 0\n",
    "    for token in word_tokenize(text):\n",
    "        token = token.lower()\n",
    "        if token in stopwords.words('english'):\n",
    "            continue\n",
    "        try:\n",
    "            base_embedding += embeddings_index[token]\n",
    "            word_count +=1\n",
    "        except:\n",
    "            continue\n",
    "    base_embedding = base_embedding/word_count\n",
    "    embeddings.append(base_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ce08f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the array as predictor values\n",
    "X_we = np.array(embeddings, dtype='float32')\n",
    "X_train_we, X_test_we, y_train_we, y_test_we = train_test_split(X_we,y_mod, test_size=.3, random_state=0, stratify=y_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "4e1927d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model mean accuracy score with 300d word embedding :  72.75\n"
     ]
    }
   ],
   "source": [
    "#predict accuracy using logistic regression\n",
    "LR_model_1=LogisticRegression(C=10000)\n",
    "LR_accuracy_we = cross_validate(LR_model_1,  X_train_we, y_train_we, scoring='accuracy', cv=cv)#calculate accuracy of model\n",
    "print(f\"Logistic Regression model mean accuracy score with 300d word embedding : \",round(np.mean(LR_accuracy_we['test_score'])*100,2))#print accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83d0f04",
   "metadata": {},
   "source": [
    "#### With Neural Network model on 300 dim word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "ce7f74e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the neural network model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "NN_model = MLPClassifier(solver='adam',random_state=0, max_iter=500)#declare the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "b116e90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of sample accuracy score of Nural Network Classifier model with 300d word embedding :  70.61\n",
      "With 300 word embedding Neural network model mean accuracy score : 72.43\n"
     ]
    }
   ],
   "source": [
    "#predict accuracy using neural network model\n",
    "NN_model.fit(X_train_we, y_train_we)\n",
    "NN_y_test_hat = NN_model.predict(X_test_we)\n",
    "NN_out_acc = accuracy_score(y_test_we,NN_y_test_hat, normalize=True)\n",
    "print(f\"Out of sample accuracy score of Nural Network Classifier model with 300d word embedding : \",round(NN_out_acc*100,2))\n",
    "NN_accuracy = cross_validate(NN_model,  X_train_we, y_train_we, scoring='accuracy', cv=cv)#calculate accuracy of model\n",
    "print(f\"With 300 word embedding Neural network model mean accuracy score :\", round(np.mean(NN_accuracy['test_score'])*100,2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6524bad",
   "metadata": {},
   "source": [
    "#### With Support Vector Classification model on 300 dim word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d896ad4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of sample accuracy score of SVM Classifier with 300d word embedding: 74.3\n",
      "SVM Classifier model mean accuracy score with 300d word embedding :  74.71\n"
     ]
    }
   ],
   "source": [
    "#initialize and predict accuracy using SVM model\n",
    "from sklearn.svm import SVC\n",
    "SVM_model = SVC(kernel='rbf',C=5, gamma=.1)\n",
    "SVM_model.fit(X_train_we, y_train_we)\n",
    "y_test_hat = SVM_model.predict(X_test_we)\n",
    "print(\"Out of sample accuracy score of SVM Classifier with 300d word embedding: {}\".format(round(accuracy_score(y_test_we,y_test_hat) * 100,2)))\n",
    "SVM_accuracy_we = cross_validate(SVM_model,  X_train_we, y_train_we, scoring='accuracy', cv=cv)#calculate accuracy of model\n",
    "print(f\"SVM Classifier model mean accuracy score with 300d word embedding : \",round(np.mean(SVM_accuracy_we['test_score'])*100,2))#print accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed67cc3",
   "metadata": {},
   "source": [
    "#### With stochastic gradient descent model on 300 dim word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "c744f783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for SGDClassifier: 72.61\n"
     ]
    }
   ],
   "source": [
    "#initialize and predict accuracy using SGD classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "SGD_model = SGDClassifier(alpha=.001)\n",
    "SGD_model.fit(X_train_we, y_train_we)\n",
    "y_test_hat = SGD_model.predict(X_test_we)\n",
    "print(\"Accuracy for SGDClassifier: {}\".format(round(accuracy_score(y_test_we,y_test_hat) * 100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7d502a",
   "metadata": {},
   "source": [
    "<ul><h5>So far our best model is SVM model, we shall fit this model with whole dataset</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6bbef5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=5, gamma=0.1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the whole data with best accuracy model(SVM)\n",
    "SVM_model.fit(X_we, y_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cd4290fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(SVM_model, open('SVM_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd57f645",
   "metadata": {},
   "source": [
    "### Topic modelling with LatentDirichletAllocation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "f48fb3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "vect = CountVectorizer(max_features=10000, max_df=.60, \n",
    "                       stop_words=\"english\")\n",
    "X_lda = vect.fit_transform(data_mod)\n",
    "lda = LatentDirichletAllocation(n_components=10, learning_method=\"batch\",\n",
    "                                max_iter=50, random_state=0) \n",
    "document_topics = lda.fit_transform(X_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "ab615fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['young',\n",
       "  'woman',\n",
       "  'family',\n",
       "  'father',\n",
       "  'home',\n",
       "  'night',\n",
       "  'life',\n",
       "  'man',\n",
       "  'mother',\n",
       "  'husband'],\n",
       " 1: ['film',\n",
       "  'documentary',\n",
       "  'life',\n",
       "  'story',\n",
       "  'world',\n",
       "  'new',\n",
       "  'history',\n",
       "  'look',\n",
       "  'music',\n",
       "  'interviews'],\n",
       " 2: ['school',\n",
       "  'friends',\n",
       "  'high',\n",
       "  'new',\n",
       "  'love',\n",
       "  'best',\n",
       "  'friend',\n",
       "  'college',\n",
       "  'old',\n",
       "  'time'],\n",
       " 3: ['life',\n",
       "  'family',\n",
       "  'story',\n",
       "  'father',\n",
       "  'new',\n",
       "  'mother',\n",
       "  'son',\n",
       "  'young',\n",
       "  'home',\n",
       "  'years'],\n",
       " 4: ['team',\n",
       "  'story',\n",
       "  'world',\n",
       "  'years',\n",
       "  'football',\n",
       "  'game',\n",
       "  'set',\n",
       "  'group',\n",
       "  'player',\n",
       "  'band'],\n",
       " 5: ['war',\n",
       "  'world',\n",
       "  'story',\n",
       "  'lives',\n",
       "  'film',\n",
       "  'american',\n",
       "  'young',\n",
       "  'united',\n",
       "  'america',\n",
       "  'new'],\n",
       " 6: ['new',\n",
       "  'los',\n",
       "  'life',\n",
       "  'angeles',\n",
       "  'young',\n",
       "  'comedy',\n",
       "  'town',\n",
       "  'la',\n",
       "  'sister',\n",
       "  'small'],\n",
       " 7: ['love',\n",
       "  'young',\n",
       "  'life',\n",
       "  'story',\n",
       "  'lives',\n",
       "  'man',\n",
       "  'new',\n",
       "  'world',\n",
       "  'relationship',\n",
       "  'woman'],\n",
       " 8: ['life',\n",
       "  'young',\n",
       "  'woman',\n",
       "  'love',\n",
       "  'mother',\n",
       "  'girl',\n",
       "  'man',\n",
       "  'make',\n",
       "  'meets',\n",
       "  'day'],\n",
       " 9: ['group',\n",
       "  'night',\n",
       "  'evil',\n",
       "  'mysterious',\n",
       "  'killer',\n",
       "  'man',\n",
       "  'horror',\n",
       "  'dead',\n",
       "  'family',\n",
       "  'terrifying']}"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "# Get features (tokens) from CountVectorizer\n",
    "feature_names = np.array(vect.get_feature_names_out())\n",
    "# Find top n tokens\n",
    "topics = dict()\n",
    "for idx, component in enumerate(lda.components_): \n",
    "    top_n_indices = component.argsort()[:-(n + 1): -1] \n",
    "    topic_tokens = [feature_names[i] for i in top_n_indices] \n",
    "    topics[idx] = topic_tokens\n",
    "\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2f1a42d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the tokens and get top 2 tokens in each topic\n",
    "sorting = np.argsort(lda.components_, axis=1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names())\n",
    "topic_names = [\"{:>2} \".format(i) + \" \".join(words) \n",
    "               for i, words in enumerate(feature_names[sorting[:, :2]])] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0881abd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "n_topics=10\n",
    "\n",
    "# two column bar chart:\n",
    "for col in [0, 1]: \n",
    "    start = col*int(n_topics/2)\n",
    "    end=(col+1)*int(n_topics/2)\n",
    "    ax[col].barh(np.arange(int(n_topics/2)), np.sum(document_topics, axis=0)[start:end]) \n",
    "    ax[col].set_yticks(np.arange(int(n_topics/2))) \n",
    "    ax[col].set_yticklabels(topic_names[start:end], ha=\"left\", va=\"top\") \n",
    "    ax[col].invert_yaxis()\n",
    "    ax[col].set_xlim(0, 2000)\n",
    "    yax = ax[col].get_yaxis()\n",
    "    yax.set_tick_params(pad=130)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52448577",
   "metadata": {},
   "source": [
    "### Check our model with evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26107e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122349</td>\n",
       "      <td>Growing up in the Mission district of San Fran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122351</td>\n",
       "      <td>A soldier returns home from the Iraq war only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122361</td>\n",
       "      <td>Marco the Monkey works as a beach officer. But...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>187901</td>\n",
       "      <td>When an honest cop, Vijay Kumar\\'s family is r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>187903</td>\n",
       "      <td>Kathiresan aka Kaththi, a criminal, escapes fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                              story\n",
       "0    122349  Growing up in the Mission district of San Fran...\n",
       "1    122351  A soldier returns home from the Iraq war only ...\n",
       "2    122361  Marco the Monkey works as a beach officer. But...\n",
       "3    187901  When an honest cop, Vijay Kumar\\'s family is r...\n",
       "4    187903  Kathiresan aka Kaththi, a criminal, escapes fr..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a datframe with the evaluation dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score,f1_score, recall_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "#ignore warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "eval_df = pd.read_csv(\"movie_story_evaluation_file.csv\")\n",
    "genre_df=pd.read_csv(\"movies.csv\")\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56dbb2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>story</th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122349</td>\n",
       "      <td>Growing up in the Mission district of San Fran...</td>\n",
       "      <td>122349</td>\n",
       "      <td>La Mission (2009)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122351</td>\n",
       "      <td>A soldier returns home from the Iraq war only ...</td>\n",
       "      <td>122351</td>\n",
       "      <td>Stir of Echoes: The Homecoming (2007)</td>\n",
       "      <td>Horror|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122361</td>\n",
       "      <td>Marco the Monkey works as a beach officer. But...</td>\n",
       "      <td>122361</td>\n",
       "      <td>Primates of the Caribbean (2012)</td>\n",
       "      <td>Animation|Children|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>187901</td>\n",
       "      <td>When an honest cop, Vijay Kumar\\'s family is r...</td>\n",
       "      <td>187901</td>\n",
       "      <td>Theri (2016)</td>\n",
       "      <td>Action|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>187903</td>\n",
       "      <td>Kathiresan aka Kaththi, a criminal, escapes fr...</td>\n",
       "      <td>187903</td>\n",
       "      <td>Kaththi (2014)</td>\n",
       "      <td>Action|Drama|Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                              story  movieId  \\\n",
       "0    122349  Growing up in the Mission district of San Fran...   122349   \n",
       "1    122351  A soldier returns home from the Iraq war only ...   122351   \n",
       "2    122361  Marco the Monkey works as a beach officer. But...   122361   \n",
       "3    187901  When an honest cop, Vijay Kumar\\'s family is r...   187901   \n",
       "4    187903  Kathiresan aka Kaththi, a criminal, escapes fr...   187903   \n",
       "\n",
       "                                   title                     genres  \n",
       "0                      La Mission (2009)                      Drama  \n",
       "1  Stir of Echoes: The Homecoming (2007)            Horror|Thriller  \n",
       "2       Primates of the Caribbean (2012)  Animation|Children|Comedy  \n",
       "3                           Theri (2016)             Action|Romance  \n",
       "4                         Kaththi (2014)       Action|Drama|Romance  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "comb_eval_df = pd.merge(eval_df, genre_df, left_on='movie_id', right_on='movieId')\n",
    "comb_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bba7fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>story</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122349</td>\n",
       "      <td>Growing up in the Mission district of San Fran...</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122351</td>\n",
       "      <td>A soldier returns home from the Iraq war only ...</td>\n",
       "      <td>Horror|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122361</td>\n",
       "      <td>Marco the Monkey works as a beach officer. But...</td>\n",
       "      <td>Animation|Children|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>187901</td>\n",
       "      <td>When an honest cop, Vijay Kumar\\'s family is r...</td>\n",
       "      <td>Action|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>187903</td>\n",
       "      <td>Kathiresan aka Kaththi, a criminal, escapes fr...</td>\n",
       "      <td>Action|Drama|Romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                              story  \\\n",
       "0    122349  Growing up in the Mission district of San Fran...   \n",
       "1    122351  A soldier returns home from the Iraq war only ...   \n",
       "2    122361  Marco the Monkey works as a beach officer. But...   \n",
       "3    187901  When an honest cop, Vijay Kumar\\'s family is r...   \n",
       "4    187903  Kathiresan aka Kaththi, a criminal, escapes fr...   \n",
       "\n",
       "                      genres  \n",
       "0                      Drama  \n",
       "1            Horror|Thriller  \n",
       "2  Animation|Children|Comedy  \n",
       "3             Action|Romance  \n",
       "4       Action|Drama|Romance  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge the two dataframes using common identifier movieid and create a new dataframe\n",
    "comb_eval_df= comb_eval_df.drop(columns=['movieId','title'], axis=1)\n",
    "comb_eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af561a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the filters \n",
    "comb_eval_df = comb_eval_df[comb_eval_df[\"genres\"].str.contains(\"no genres listed\") == False]\n",
    "drama = comb_eval_df['genres'].str.contains('Drama','drama')\n",
    "not_drama= comb_eval_df['genres'].str.contains('Drama','drama')==False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9733514f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply filters on the dataset\n",
    "comb_eval_df.genres[drama]= 1\n",
    "comb_eval_df.genres[not_drama]=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71c53817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the columns\n",
    "comb_eval_df = comb_eval_df.rename(columns={'movie_id':'movieid', 'genres':'DramaGenre'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b8b21cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import regex module\n",
    "import re\n",
    "# function for text cleaning \n",
    "def clean_text(text):\n",
    "    # remove backslash-and subsequent charecters and digits\n",
    "    text= re.sub(r'\\\\\\w.+?\\d*','',text) \n",
    "    #remove only backslashes\n",
    "    text = re.sub(r'\\\\','',text)\n",
    "    #remove all digits from text\n",
    "    text = re.sub(r'\\d','',text)\n",
    "    #remove all non alphanumeric characters\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s]','',text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abd4aab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the dataset\n",
    "comb_eval_df['story'] = comb_eval_df['story'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f8e9f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create predictor and criterion datasets from the filtered data\n",
    "data_eval = comb_eval_df['story']\n",
    "y_eval= comb_eval_df['DramaGenre']\n",
    "y_eval=y_eval.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b743e2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(comb_eval_df, open('comb_eval_df.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0504429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A pawn shop proprietor buys used goods from desperate locals  as much to play perverse power games as for his own livelihood but when the perfect rump and a backedup toilet enter his life he loses all control'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize a random story\n",
    "data_eval[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d28011ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3302, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check shape of the new dataset\n",
    "comb_eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc5ea6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1917494it [03:22, 9450.30it/s] \n"
     ]
    }
   ],
   "source": [
    "#initialize the 300 dim glove function\n",
    "from tqdm import tqdm\n",
    "embeddings_index = dict()\n",
    "f = open('glove.42B.300d/glove.42B.300d.txt',encoding='utf-8')\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "464b9c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to embed the text data\n",
    "def embed(X):\n",
    "    import nltk\n",
    "    nltk.download('stopwords')\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.tokenize import word_tokenize\n",
    "\n",
    "    from tqdm import tqdm\n",
    "    embeddings = []\n",
    "    for text in tqdm(X):\n",
    "\n",
    "        base_embedding = np.zeros((300,))\n",
    "        word_count = 0\n",
    "        for token in word_tokenize(text):\n",
    "            token = token.lower()\n",
    "            if token in stopwords.words('english'):\n",
    "                continue\n",
    "            try:\n",
    "                base_embedding += embeddings_index[token]\n",
    "                word_count +=1\n",
    "            except:\n",
    "                continue\n",
    "        base_embedding = base_embedding/word_count\n",
    "        embeddings.append(base_embedding)\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f9787a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\manas_nmr2rze\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|██████████| 3302/3302 [00:39<00:00, 84.09it/s] \n"
     ]
    }
   ],
   "source": [
    "#initialize the predictor as embedded array\n",
    "embeddings=embed(data_eval)\n",
    "X_eval = np.array(embeddings, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce756375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with SVM Classifier on evaluation dataset: 69.81\n"
     ]
    }
   ],
   "source": [
    "#check accuracy of prediction on the evaluation dataset with our selected SVM model\n",
    "from sklearn.metrics import accuracy_score, precision_score,f1_score, recall_score\n",
    "SVM_model = pickle.load(open('SVM_model.pkl','rb'))\n",
    "y_test_hat_eval = SVM_model.predict(X_eval)\n",
    "print(\"Accuracy with SVM Classifier on evaluation dataset: {}\".format(round(accuracy_score(y_eval,y_test_hat_eval) * 100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "cab0bd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m SVM model scores: \u001b[0m\n",
      "Precision score of SVM model with evaluation dataset is:  69.95\n",
      "Recall score of SVM model with evaluation dataset is :  70.33\n",
      "F1 score of SVM model with evaluation dataset is :  69.95\n",
      "AUC score of SVM model with evaluation dataset is :  77.45\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\033[1m SVM model scores: \\033[0m\")#print model name in bold\n",
    "y_pred= SVM_model.predict(X_eval) #predict with test data\n",
    "\n",
    "pr = precision_score(y_eval, y_pred, average='macro')#calculate precision score\n",
    "print(f\"Precision score of SVM model with evaluation dataset is: \",round(pr*100,2))#print precision score\n",
    "rc = recall_score(y_eval, y_pred, average='macro')#calculate recall score\n",
    "print(f\"Recall score of SVM model with evaluation dataset is : \",round(rc*100,2))#print recall score\n",
    "f1 = f1_score(y_eval, y_pred, average='weighted')#calculate F1 score\n",
    "print(f\"F1 score of SVM model with evaluation dataset is : \",round(f1*100,2))#print F1 score\n",
    "#auc = roc_auc_score(y_eval, model.predict_proba(X_test)[:,1])\n",
    "auc = roc_auc_score(y_eval, SVM_model.decision_function(X_eval))\n",
    "print(f\"AUC score of SVM model with evaluation dataset is : \",round(auc*100,2))#print roc_auc score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f47833",
   "metadata": {},
   "source": [
    "### Prediction function which takes MovieId as input and tells if the Genre is Drama or Not Drama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f4f3580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to predict genre of an individual movie(if it belongs to Drama or not Drama)\n",
    "def predict_genre():\n",
    "    import pickle\n",
    "    \n",
    "    SVM_model = pickle.load(open('SVM_model.pkl','rb'))\n",
    "    comb_eval_df = pickle.load(open('comb_eval_df.pkl','rb'))\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    num = int(input(\"Enter movie ID: \"))\n",
    "    h=pd.DataFrame(comb_eval_df.loc[(comb_eval_df.movieid==num)]).reset_index()\n",
    "    X=h.story[0]\n",
    "    y=np.array(h.DramaGenre)\n",
    "    \n",
    "\n",
    "    text= clean_text(X)\n",
    "    gen = embed(text)\n",
    "    x_ev=np.array(gen, dtype='float32')\n",
    "    x= np.nan_to_num(x_ev)\n",
    "    a,b=x.shape\n",
    "    c= np.ones(a,)\n",
    "    y= y*c\n",
    "    y= y.astype('int32')\n",
    "\n",
    "    pre = SVM_model.predict(x)\n",
    "    ac= accuracy_score(y,pre)\n",
    "\n",
    "    if (1-ac)>.5:\n",
    "        print(\"Drama genre\")\n",
    "    else:\n",
    "        print(\"Not drama genre\")\n",
    "    print()\n",
    "    print(\"Story:\")\n",
    "    print(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "id": "68ef6bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieid</th>\n",
       "      <th>story</th>\n",
       "      <th>DramaGenre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122349</td>\n",
       "      <td>Growing up in the Mission district of San Fran...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122351</td>\n",
       "      <td>A soldier returns home from the Iraq war only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122361</td>\n",
       "      <td>Marco the Monkey works as a beach officer But ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>187901</td>\n",
       "      <td>When an honest cop Vijay Kumars family is ruth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>187903</td>\n",
       "      <td>Kathiresan aka Kaththi a criminal escapes from...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>56835</td>\n",
       "      <td>At popular South Beach University filthy rich ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56837</td>\n",
       "      <td>Witty playful and utterly magical the story is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>56846</td>\n",
       "      <td>Rainbow press reporter Ludo is sentenced to  m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>122387</td>\n",
       "      <td>Nemesis is the hottest rapper in raps hottest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>187937</td>\n",
       "      <td>Jacek loves heavy metal and his dog He convert...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>56869</td>\n",
       "      <td>A pawn shop proprietor buys used goods from de...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>122406</td>\n",
       "      <td>The women of a remote Latin American town are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>187941</td>\n",
       "      <td>The most feared battle emcee in earlys NYC was...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>187943</td>\n",
       "      <td>One night in the hottest summer in  years Lean...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>187945</td>\n",
       "      <td>A newly reunited young couples drive through t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>122419</td>\n",
       "      <td>In search of an ancient Chinese scroll a Chine...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>56885</td>\n",
       "      <td>The true story of a brilliant but politically ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>187957</td>\n",
       "      <td>Hari Kondabolu breaks down identity politics c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>187959</td>\n",
       "      <td>An internet broadcaster recruits a handful of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>56888</td>\n",
       "      <td>Bilike has never seen a pingpong ball before H...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    movieid                                              story DramaGenre\n",
       "0    122349  Growing up in the Mission district of San Fran...          1\n",
       "1    122351  A soldier returns home from the Iraq war only ...          0\n",
       "2    122361  Marco the Monkey works as a beach officer But ...          0\n",
       "3    187901  When an honest cop Vijay Kumars family is ruth...          0\n",
       "4    187903  Kathiresan aka Kaththi a criminal escapes from...          1\n",
       "5     56835  At popular South Beach University filthy rich ...          0\n",
       "6     56837  Witty playful and utterly magical the story is...          1\n",
       "7     56846  Rainbow press reporter Ludo is sentenced to  m...          0\n",
       "8    122387  Nemesis is the hottest rapper in raps hottest ...          1\n",
       "9    187937  Jacek loves heavy metal and his dog He convert...          1\n",
       "10    56869  A pawn shop proprietor buys used goods from de...          0\n",
       "11   122406  The women of a remote Latin American town are ...          0\n",
       "12   187941  The most feared battle emcee in earlys NYC was...          1\n",
       "13   187943  One night in the hottest summer in  years Lean...          0\n",
       "14   187945  A newly reunited young couples drive through t...          0\n",
       "15   122419  In search of an ancient Chinese scroll a Chine...          0\n",
       "16    56885  The true story of a brilliant but politically ...          1\n",
       "17   187957  Hari Kondabolu breaks down identity politics c...          0\n",
       "18   187959  An internet broadcaster recruits a handful of ...          0\n",
       "19    56888  Bilike has never seen a pingpong ball before H...          1"
      ]
     },
     "execution_count": 939,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize the top 20 values in dataframe\n",
    "comb_eval_df.head(20)\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d84921e",
   "metadata": {},
   "source": [
    "##### Predict with the prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5caefa71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter movie ID: 56837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\manas_nmr2rze\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|██████████| 252/252 [00:00<00:00, 3422.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drama genre\n",
      "\n",
      "Story:\n",
      "Witty playful and utterly magical the story is a compelling romantic adventure in which Rosalind and Orlandos celebrated courtship is played out against a backdrop of political rivalry banishment and exile in the Forest of Arden  set in thcentury Japan\n"
     ]
    }
   ],
   "source": [
    "#run the function to predict the genre of movie by taking movie id as user input\n",
    "predict_genre()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa63de9",
   "metadata": {},
   "source": [
    "<ul><b>It looks like our model is working nicely and accurately to predict genre of an individual movie by reading through the story of that movie</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
